import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
import time  # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ç”¨

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ– ---
if 'model' not in st.session_state:
    st.session_state.model = None

# --- ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆè»½é‡ç‰ˆï¼š50ä»¶ï¼‰ ---
def augment_data(df, num_augments=50, noise_std=0.5, time_scale_range=(0.95, 1.05), temp_shift_range=(-2, 2)):
    aug_dfs = []
    progress = st.progress(0)
    status = st.empty()

    for idx in range(num_augments):
        temp = df.copy()

        temp["T_internal"] += np.random.normal(0, noise_std, size=len(temp))
        scale = np.random.uniform(*time_scale_range)
        temp["time"] = temp["time"] * scale
        shift = np.random.uniform(*temp_shift_range)
        temp["T_internal"] += shift
        temp["T_surface"] += shift

        aug_dfs.append(temp)

        progress.progress((idx + 1) / num_augments)
        status.text(f"ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µä¸­... {idx+1}/{num_augments}")

    status.text("âœ… ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå®Œäº†")
    return pd.concat(aug_dfs, ignore_index=True)

# --- LSTMãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ ---
def create_sequences(df, window_size=20):
    X, y = [], []
    for i in range(len(df) - window_size):
        seq_x = df["T_internal"].iloc[i:i+window_size].values
        seq_y = df["T_surface"].iloc[i+window_size]
        X.append(seq_x)
        y.append(seq_y)
    return np.array(X), np.array(y)

def build_lstm_model(input_shape):
    model = Sequential()
    model.add(LSTM(32, input_shape=input_shape))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mse')
    return model

def train_lstm_with_progress(model, X, y, epochs=10, batch_size=32):
    progress = st.progress(0)
    status = st.empty()
    for epoch in range(epochs):
        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0)
        progress.progress((epoch + 1) / epochs)
        status.text(f"LSTMå­¦ç¿’ä¸­... ã‚¨ãƒãƒƒã‚¯ {epoch+1}/{epochs}")
    status.text("âœ… LSTMå­¦ç¿’å®Œäº†")
    return model

# --- ã‚µã‚¤ã‚¯ãƒ«æ¤œå‡ºï¼†åˆ‡ã‚Šå‡ºã— ---
def extract_cycles(df, start_col, lag_sec, duration_sec, sampling=0.1):
    starts = df[df[start_col].diff() == 1].index
    lag_steps = int(lag_sec / sampling)
    duration_steps = int(duration_sec / sampling)
    segments = []
    for s in starts:
        t_start = s + lag_steps
        t_end = t_start + duration_steps
        if t_end <= len(df):
            segments.append(df.iloc[t_start:t_end].copy())
    return pd.concat(segments, ignore_index=True) if segments else pd.DataFrame()

# --- Streamlitã‚¢ãƒ—ãƒªæœ¬ä½“ ---
st.set_page_config(page_title="LSTMã«ã‚ˆã‚‹T_surfaceäºˆæ¸¬ï¼ˆè»½é‡ç‰ˆï¼‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜ï¼‰", layout="wide")
st.title("ğŸŒ¡ï¸ LSTMç‰ˆ T_surface å¤šç‚¹äºˆæ¸¬ã‚¢ãƒ—ãƒªï¼ˆè»½é‡ç‰ˆãƒ»å­¦ç¿’ã‚¹ã‚­ãƒƒãƒ—å¯¾å¿œï¼‰")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.header("â±ï¸ æ™‚é–“è¨­å®š")
lag_seconds = st.sidebar.number_input("ç«‹ã¡ä¸ŠãŒã‚Šãƒ©ã‚°ï¼ˆç§’ï¼‰", min_value=0.0, max_value=30.0, value=5.0, step=0.5)
duration_seconds = st.sidebar.number_input("äºˆæ¸¬ã™ã‚‹æ™‚é–“ç¯„å›²ï¼ˆç§’ï¼‰", min_value=5.0, max_value=120.0, value=55.0, step=1.0)
sampling_rate = 0.1
window_size = 20

# --- 1. å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
st.header("1ï¸âƒ£ å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
train_file = st.file_uploader("T_internal, T_surface, start_signalã‚’å«ã‚€CSV", type="csv")

if train_file:
    df = pd.read_csv(train_file)
    if set(["T_internal", "T_surface", "start_signal"]).issubset(df.columns):
        base_segment = extract_cycles(df, "start_signal", lag_seconds, duration_seconds, sampling_rate)
        st.subheader("ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µä¸­...")
        aug_train_df = augment_data(base_segment, num_augments=50)

        X, y = create_sequences(aug_train_df, window_size)
        X = X.reshape((X.shape[0], X.shape[1], 1))

        model = build_lstm_model((window_size, 1))
        st.subheader("ğŸ”„ LSTMå­¦ç¿’ä¸­...")
        model = train_lstm_with_progress(model, X, y, epochs=10)
        st.success("âœ… ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")

        # âœ… ãƒ¢ãƒ‡ãƒ«ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
        st.session_state.model = model
    else:
        st.error("å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

# --- 2. äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
st.header("2ï¸âƒ£ äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
test_file = st.file_uploader("T_internal1ã€œ5, start_signalã‚’å«ã‚€CSV", type="csv")

def prepare_predict_sequences(df, window_size=20):
    X = []
    for i in range(len(df) - window_size):
        seq_x = df.iloc[i:i+window_size].values
        X.append(seq_x)
    return np.array(X)

if st.session_state.model and test_file:
    model = st.session_state.model  # âœ… ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«å–å¾—
    df_test = pd.read_csv(test_file)
    
    if "start_signal" not in df_test.columns:
        st.error("start_signalåˆ—ãŒã‚ã‚Šã¾ã›ã‚“")
    else:
        internal_cols = [col for col in df_test.columns if col.startswith("T_internal")]
        if not internal_cols:
            st.error("T_internal1ã€œ5åˆ—ãŒå¿…è¦ã§ã™")
        else:
            progress = st.progress(0)
            status = st.empty()
            all_preds = []

            for idx, col in enumerate(internal_cols):
                temp_df = df_test[["time", col, "start_signal"]].rename(columns={col: "T_internal"})
                segments = extract_cycles(temp_df, "start_signal", lag_seconds, duration_seconds, sampling_rate)
                if not segments.empty:
                    X_pred = prepare_predict_sequences(segments["T_internal"], window_size)
                    X_pred = X_pred.reshape((X_pred.shape[0], X_pred.shape[1], 1))
                    y_pred = model.predict(X_pred)
                    result_df = segments.iloc[window_size:].copy()
                    result_df[f"Predicted_T_surface_{col}"] = y_pred.flatten()
                    all_preds.append(result_df.set_index("time")[[f"Predicted_T_surface_{col}"]])

                progress.progress((idx + 1) / len(internal_cols))
                status.text(f"äºˆæ¸¬ä¸­... {idx+1}/{len(internal_cols)}å€‹å®Œäº†")

            if all_preds:
                result_df = pd.concat(all_preds, axis=1).reset_index()

                # --- äºˆæ¸¬çµæœè¡¨ç¤º ---
                st.subheader("ğŸ“Š äºˆæ¸¬çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                st.dataframe(result_df.head())

                # --- ã‚°ãƒ©ãƒ•æç”» ---
                st.subheader("ğŸ“ˆ å…¥åŠ›vsäºˆæ¸¬ã‚°ãƒ©ãƒ•")
                fig, axes = plt.subplots(len(internal_cols), 1, figsize=(10, 2.5 * len(internal_cols)), sharex=True)
                time_vals = result_df["time"]
                for i, col in enumerate(internal_cols):
                    ax = axes[i]
                    pred_col = f"Predicted_T_surface_{col}"
                    original_trimmed = df_test[col][len(df_test) - len(time_vals):].values
                    ax.plot(time_vals, original_trimmed, label=col, color="tab:blue")
                    ax.plot(time_vals, result_df[pred_col], label=pred_col, color="tab:red", linestyle="--")
                    ax.set_ylabel("æ¸©åº¦ [Â°C]")
                    ax.set_title(f"{col} vs äºˆæ¸¬")
                    ax.legend()
                axes[-1].set_xlabel("æ™‚é–“ [s]")
                st.pyplot(fig)

                # --- CSVå‡ºåŠ› ---
                st.subheader("ğŸ’¾ äºˆæ¸¬çµæœCSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                csv_bytes = result_df.to_csv(index=False).encode("utf-8")
                st.download_button("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv_bytes, file_name="predicted_surface_lstm_light_session.csv", mime="text/csv")

            status.text("âœ… äºˆæ¸¬å®Œäº†ï¼")
